{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col, monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = \"reviews_Video_Games_5.json\"\n",
    "APP_NAME = \"AMAZON VIDEO GAME ANALYSIS\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "RANDOM_SEED = 141107\n",
    "TRAINING_DATA_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|          reviewText|             summary|overall|\n",
      "+--------------------+--------------------+-------+\n",
      "|Installing the ga...|Pay to unlock con...|    1.0|\n",
      "|If you like rally...|     Good rally game|    4.0|\n",
      "|1st shipment rece...|           Wrong key|    1.0|\n",
      "|I got this versio...|awesome game, if ...|    3.0|\n",
      "|I had Dirt 2 on X...|              DIRT 3|    4.0|\n",
      "|Overall this is a...|Good racing game,...|    4.0|\n",
      "|Loved playing Dir...|A step up from Di...|    5.0|\n",
      "|I can't tell you ...|Crash 3 is correc...|    1.0|\n",
      "|I initially gave ...|A great game ruin...|    4.0|\n",
      "|I still haven't f...|Couldn't get this...|    2.0|\n",
      "|I'm not quite fin...| Best in the series!|    5.0|\n",
      "|I have been playi...|   A 5 stars winner!|    5.0|\n",
      "|Dirt 3 on DVDi co...|                Cars|    5.0|\n",
      "|I bought this and...|It might have bee...|    1.0|\n",
      "|Crashed in Vista....|Don't waste your ...|    1.0|\n",
      "|This game was a r...|Not as good as Di...|    1.0|\n",
      "|In today's game m...|An overlooked gem...|    4.0|\n",
      "|This really is a ...|Better than Dirt ...|    3.0|\n",
      "|This game is bug ...|Colin McRae CRASH 3!|    1.0|\n",
      "|DiRT 2 was like t...|The first one was...|    1.0|\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['reviewText', 'summary', 'overall']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn('target', when(df.overall < 3, 0).otherwise(1))\n",
    "df2 = df2.withColumn('id', monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.select(['id', 'reviewText', 'target'])\n",
    "df2 = df2.selectExpr(\"id as id\", \"reviewText as reviewText\", \"target as label\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "| id|          reviewText|label|\n",
      "+---+--------------------+-----+\n",
      "|  0|Installing the ga...|    0|\n",
      "|  1|If you like rally...|    1|\n",
      "|  2|1st shipment rece...|    0|\n",
      "|  3|I got this versio...|    1|\n",
      "|  4|I had Dirt 2 on X...|    1|\n",
      "+---+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, id: string, reviewText: string, label: string]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, valdata, testData) = df2.randomSplit([0.75, 0.05, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "| id|          reviewText|label|               words|                  tf|            features|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|  0|Installing the ga...|    0|[installing, the,...|(65536,[14,680,16...|(65536,[14,680,16...|\n",
      "|  1|If you like rally...|    1|[if, you, like, r...|(65536,[2410,3092...|(65536,[2410,3092...|\n",
      "|  2|1st shipment rece...|    0|[1st, shipment, r...|(65536,[568,6534,...|(65536,[568,6534,...|\n",
      "|  3|I got this versio...|    1|[i, got, this, ve...|(65536,[14,672,73...|(65536,[14,672,73...|\n",
      "|  6|Loved playing Dir...|    1|[loved, playing, ...|(65536,[4461,4488...|(65536,[4461,4488...|\n",
      "|  7|I can't tell you ...|    0|[i, can't, tell, ...|(65536,[1903,2026...|(65536,[1903,2026...|\n",
      "|  9|I still haven't f...|    0|[i, still, haven'...|(65536,[3053,3149...|(65536,[3053,3149...|\n",
      "| 12|Dirt 3 on DVDi co...|    1|[dirt, 3, on, dvd...|(65536,[8436,1606...|(65536,[8436,1606...|\n",
      "| 13|I bought this and...|    0|[i, bought, this,...|(65536,[5782,8436...|(65536,[5782,8436...|\n",
      "| 14|Crashed in Vista....|    0|[crashed, in, vis...|(65536,[4775,8315...|(65536,[4775,8315...|\n",
      "| 15|This game was a r...|    0|[this, game, was,...|(65536,[4807,7823...|(65536,[4807,7823...|\n",
      "| 16|In today's game m...|    1|[in, today's, gam...|(65536,[495,597,6...|(65536,[495,597,6...|\n",
      "| 17|This really is a ...|    1|[this, really, is...|(65536,[14,2410,3...|(65536,[14,2410,3...|\n",
      "| 20|lot of people don...|    1|[lot, of, people,...|(65536,[8436,8443...|(65536,[8436,8443...|\n",
      "| 21|I would like give...|    0|[i, would, like, ...|(65536,[876,3331,...|(65536,[876,3331,...|\n",
      "| 23|This is a pretty ...|    1|[this, is, a, pre...|(65536,[14,395,11...|(65536,[14,395,11...|\n",
      "| 24|This is a must ha...|    1|[this, is, a, mus...|(65536,[14,1386,2...|(65536,[14,1386,2...|\n",
      "| 25|Works good, howev...|    1|[works, good,, ho...|(65536,[1776,8026...|(65536,[1776,8026...|\n",
      "| 26|I bought this mic...|    1|[i, bought, this,...|(65536,[319,1109,...|(65536,[319,1109,...|\n",
      "| 27|I love it! Use it...|    1|[i, love, it!, us...|(65536,[14,2711,4...|(65536,[14,2711,4...|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol=\"tf\")\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"features\", minDocFreq=5)\n",
    "#label_stringIdx = StringIndexer(inputCol=\"target\", outputCol=\"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf])\n",
    "\n",
    "pipelineFit = pipeline.fit(trainingData)\n",
    "train_df = pipelineFit.transform(trainingData)\n",
    "val_df = pipelineFit.transform(valdata)\n",
    "train_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7731273946108982"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8601098523858565"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(valdata.count())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.37242696345525994\n",
      "0.36747978037055307\n",
      "0.2172428043542674\n",
      "0.21044448387860779\n",
      "0.201038144538252\n",
      "0.1902843305032753\n",
      "0.16444707949592013\n",
      "0.12220656556972752\n",
      "0.1038736324619234\n",
      "0.08763903232477989\n",
      "0.07307897351337096\n",
      "0.05944152495886717\n",
      "0.048882329344237724\n",
      "0.04078534869619423\n",
      "0.03598293278738764\n",
      "0.033316883124464715\n",
      "0.029682603876424424\n",
      "0.0279667364954938\n",
      "0.026447694829654516\n",
      "0.02512379231308338\n",
      "0.02318798352794172\n",
      "0.020955419535567257\n",
      "0.01977897242508195\n",
      "0.01844721153465085\n",
      "0.017598963321332244\n",
      "0.015517336514773775\n",
      "0.014625778316414442\n",
      "0.013726680419138333\n",
      "0.012991330375688228\n",
      "0.012771698125944314\n",
      "0.011757426177096986\n",
      "0.011268124458822266\n",
      "0.011225534949295492\n",
      "0.010884935005635895\n",
      "0.01059317659639743\n",
      "0.009988161887115304\n",
      "0.009370831492537902\n",
      "0.008800681538224622\n",
      "0.008239349179955795\n",
      "0.008172104730081418\n",
      "0.007746736069733923\n",
      "0.0072677264257551225\n",
      "0.006966796275422881\n",
      "0.006731401721400024\n",
      "0.006242903230396815\n",
      "0.005901454366127099\n",
      "0.0056613838117998\n",
      "0.005400209591439017\n",
      "0.005327192494304733\n",
      "0.005078573628429334\n",
      "0.0046555948636908175\n",
      "0.004521644360905155\n",
      "0.004471437647053381\n",
      "0.0042609891411921775\n",
      "0.004067033537643364\n",
      "0.003980106765688843\n",
      "0.0038420497887301694\n",
      "0.003709432462036849\n",
      "0.0035389151413029105\n",
      "0.003435176479251596\n",
      "0.003306666772976396\n",
      "0.0031985471987510785\n",
      "0.0031237112730979626\n",
      "0.0029600104578278406\n",
      "0.002765148323086531\n",
      "0.002673308663875309\n",
      "0.0025789113092999217\n",
      "0.0025729242600808474\n",
      "0.00253478143727079\n",
      "0.0024996134222097727\n",
      "0.0024597639784030593\n",
      "0.002420645226839257\n",
      "0.0023110932784949027\n",
      "0.0022220386902157903\n",
      "0.0021741200321697927\n",
      "0.002102169174537338\n",
      "0.002012353747415895\n",
      "0.0019137850541430623\n",
      "0.0018743572676863467\n",
      "0.0018195613753478723\n",
      "0.0017688770962940347\n",
      "0.001714316319677279\n",
      "0.0016141120252623846\n",
      "0.0015781712888616435\n",
      "0.0015208161499853975\n",
      "0.0015084393739831458\n",
      "0.0014992317045572324\n",
      "0.001486867223298342\n",
      "0.0014580770077917277\n",
      "0.0014250758630163388\n",
      "0.0013757696346178255\n",
      "0.0013298904406429284\n",
      "0.0012957478791611246\n",
      "0.001266684597239084\n",
      "0.0012350112494785386\n",
      "0.0012144555438422737\n",
      "0.0011769117672584847\n",
      "0.001126515505088785\n",
      "0.0011058083025801916\n",
      "0.001077569886823749\n",
      "0.0010366630099617475\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lrModel.summary\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate by label:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BinaryLogisticRegressionTrainingSummary' object has no attribute 'falsePositiveRateByLabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-74a73a541c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"False positive rate by label:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalsePositiveRateByLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label %d: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True positive rate by label:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BinaryLogisticRegressionTrainingSummary' object has no attribute 'falsePositiveRateByLabel'"
     ]
    }
   ],
   "source": [
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
